{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d074ec94-b66f-4c45-bd04-10b1049275d5",
   "metadata": {},
   "source": [
    "- This project serves to locate anomalies within images using a deep learning approach\n",
    "- To identify anomalous regions, pre-trained convolutional neural networks (VGG16), heatmap generation, and peak detection within those heatmaps are      leveraged\n",
    "- The model first classifies the entire image and subsequently locates the anomalous regions by analyzing activations in the final convolutional layers. Peaks in the heatmap, generated from weighted contributions of the convolutional filters, pinpoint the exact areas of the anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672cf544-e11d-4322-900e-79ab53e19cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Necessary Imports\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.patches import Rectangle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.feature.peak import peak_local_max \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7209885-59ea-4092-8698-92c3b838bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate and read images\n",
    "outer_image_dir = f'{directory_1}/'\n",
    "SIZE, dataset, label = 224, [], []\n",
    "anomaly_images = os.listdir(outer_image_dir + f'{path_to_infected_images}/')\n",
    "uninfected_images = os.listdir(outer_image_dir + f'{path_to_uninfected_images}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4aa33a-58aa-45d0-8e8d-68cb1cbd984f",
   "metadata": {},
   "source": [
    "1. Iterate over each file in the directory and check if the file extension is 'png'   \n",
    "2. Read the image using OpenCV and convert the image to a PIL Image object               \n",
    "3. Resize the image to the specified SIZE and append the image (as a numpy array) to the dataset list     \n",
    "4. Append the label '1' to the label list (assuming '1' indicates an anomaly) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92072bc3-aa6c-49fc-b6cc-e5079e5ff526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_name in enumerate(anomaly_images):\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(outer_image_dir + f'{path_to_infected_images}/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882a400-5067-465c-84f4-3134e05857ef",
   "metadata": {},
   "source": [
    "Perform testing code to ensure output is consistent with expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbe413-8be9-46ec-a7c8-d2ab7cd8f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first image in the dataset and its label\n",
    "if dataset:\n",
    "    print(f'First image shape: {dataset[0].shape}')\n",
    "    print(f'First label: {label[0]}')\n",
    "else:\n",
    "    print('No images found or loaded')\n",
    "\n",
    "\n",
    "# Check the length of dataset and label lists to ensure they match\n",
    "print(f'Total images loaded: {len(dataset)}')\n",
    "print(f'Total labels: {len(label)}')\n",
    "\n",
    "\n",
    "# Ensure the dataset contains only numpy arrays of the specified size\n",
    "for img in dataset:\n",
    "    assert isinstance(img, np.ndarray), \"Dataset contains non-numpy array elements\"\n",
    "    assert img.shape == (SIZE[1], SIZE[0], 3), \"Image size mismatch\"\n",
    "\n",
    "print(\"All images are loaded and verified successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f3508-e662-4e0a-9d78-685e359c2fc3",
   "metadata": {},
   "source": [
    "1. Iterate over each file in the directory and check if the file extension is 'png'   \n",
    "2. Read the image using OpenCV and convert the image to a PIL Image object               \n",
    "3. Resize the image to the specified SIZE and append the image (as a numpy array) to the dataset list     \n",
    "4. Append the label '0' to the label list (assuming '0' indicates a non-anomaly)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3a638-d933-48f6-81e2-3472d779880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_name in enumerate(uninfected_images):\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(outer_image_dir + f'{path_to_uninfected_images}/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "        \n",
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8cb6a-67e8-4b79-9d87-7df4cc372104",
   "metadata": {},
   "source": [
    "Convert lists to numpy arrays  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f48e18-5492-487c-9a11-765dc6b0e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea58eca-d26d-42a5-8d61-54c12cf2fa6d",
   "metadata": {},
   "source": [
    "1. Split the data into train and test data sets\n",
    "2. Perform normalization to ensure convergence occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cee50-5a9f-4133-bf16-0b73742d4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)\n",
    "\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82eade5-8adf-4083-bf94-a1a1dcdb619c",
   "metadata": {},
   "source": [
    "Converting labels to categorical format allows the model to match the label structure to the output layer (e.g., one-hot encoded format), which is necessary for using certain loss functions like categorical_crossentropy and enables correct training and evaluation in classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fb64b-d329-4b57-838c-0c9f31a42c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fda319-eaa9-454d-baeb-1153bb96e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pre-trained VGG16 layers, GlobalAveragePooling and dense prediction layers to build a model\n",
    "def model_o(input_shape=(SIZE, SIZE, 3)):\n",
    "    \n",
    "   vgg = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "   for layer in vgg.layers:\n",
    "       layer.trainable = True\n",
    "       \n",
    "   # Get the output tensor from the last layer of the VGG16 model \n",
    "   # And reduce the spatial dimensions of the feature map by computing \n",
    "   # The average of all values in each feature map\n",
    "   x = vgg.output\n",
    "   x = GlobalAveragePooling2D()(x)  \n",
    "   \n",
    "   \n",
    "   # Add a fully connected (Dense) layer with 2 units\n",
    "   # This layer outputs the final predictions, with each unit representing a class\n",
    "   x = Dense(2, activation=\"softmax\")(x) \n",
    "   \n",
    "   \n",
    "   # Create a new model by specifying the input tensor (vgg.input) and the output tensor (x)\n",
    "   # This combines the pre-trained VGG16 convolutional base with the new fully connected layer for classification\n",
    "   model = Model(vgg.input, x)\n",
    "   model.compile(loss=\"categorical_crossentropy\", \n",
    "                 optimizer=SGD(learning_rate=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "   \n",
    "   return model\n",
    "\n",
    "\n",
    "\n",
    "model = get_model(input_shape = (SIZE,SIZE,3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ad1eb-070e-409c-b425-cc4e1e4c6ef4",
   "metadata": {},
   "source": [
    "The training is done on X_train and y_train with validation using X_test and y_test. After training, it extracts the loss and accuracy metrics for both the training and validation sets from the history object, which stores the results of each epoch. The code then generates two plots: one showing the training and validation loss over epochs, and another showing the training and validation accuracy over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b753b-3f94-487c-8ff2-05180ae6e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=16, \n",
    "                    epochs=30, \n",
    "                    verbose = 1, \n",
    "                    validation_data=(X_test,y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c47302-a4e9-4fa8-b965-8e2a7ff204b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check model accuracy on the test data\n",
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "\n",
    "img = X_test[5]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) \n",
    "print(\"The prediction for this image is: \", np.argmax(model.predict(input_img)))\n",
    "print(\"The actual label for this image is: \", np.argmax(y_test[n]))\n",
    "\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "y_pred = np.argmax(model.predict(y_test, axis=1), y_pred)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "\n",
    "#Identify all images classified as anomalies\n",
    "anomaly_image_dataset = np.where(y_pred==1)[0]\n",
    "\n",
    "\n",
    "def plot_heatmap(img):\n",
    "    pred = model.predict(np.expand_dims(img, axis=0))\n",
    "    pred_class = np.argmax(pred)\n",
    "    #Get weights for all classes from the prediction layer\n",
    "    last_layer_weights = model.layers[-1].get_weights()[0] #Prediction layer\n",
    "    #Get weights for the predicted class.\n",
    "    last_layer_weights_for_pred = last_layer_weights[:, pred_class]\n",
    "    #Get output from the last conv. layer\n",
    "    last_conv_model = Model(model.input, model.get_layer(\"block5_conv3\").output)\n",
    "    last_conv_output = last_conv_model.predict(img[np.newaxis,:,:,:])\n",
    "    last_conv_output = np.squeeze(last_conv_output)\n",
    "    \n",
    "    #Upsample/resize the last conv. output to same size as original image\n",
    "    h = int(img.shape[0]/last_conv_output.shape[0])\n",
    "    w = int(img.shape[1]/last_conv_output.shape[1])\n",
    "    upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)\n",
    "    \n",
    "    heat_map = np.dot(upsampled_last_conv_output.reshape((img.shape[0]*img.shape[1], 512)), \n",
    "                 last_layer_weights_for_pred).reshape(img.shape[0],img.shape[1])\n",
    "    \n",
    "    #Since we have a lot of dark pixels where the edges may be thought of as \n",
    "    #high anomaly, let us drop all heat map values in this region to 0.\n",
    "    #This is an optional step based on the image. \n",
    "    heat_map[img[:,:,0] == 0] = 0  #All dark pixels outside the object set to 0\n",
    "    \n",
    "    #Detect peaks (hot spots) in the heat map. We will set it to detect maximum 5 peaks.\n",
    "    #with rel threshold of 0.5 (compared to the max peak). \n",
    "    peak_coords = peak_local_max(heat_map, num_peaks=5, threshold_rel=0.5, min_distance=10) \n",
    "\n",
    "    plt.imshow(img.astype('float32').reshape(img.shape[0],img.shape[1],3))\n",
    "    plt.imshow(heat_map, cmap='jet', alpha=0.30)\n",
    "    for i in range(0,peak_coords.shape[0]):\n",
    "        print(i)\n",
    "        y = peak_coords[i,0]\n",
    "        x = peak_coords[i,1]\n",
    "        plt.gca().add_patch(Rectangle((x-25, y-25), 50,50,linewidth=1,edgecolor='r',facecolor='none'))\n",
    "        \n",
    "        \n",
    "\n",
    "im = random.randint(0,predicted_as_para.shape[0]-1)\n",
    "heat_map =plot_heatmap(predicted_as_para[im])\n",
    "\n",
    "img = predicted_as_para[im]\n",
    "plt.imshow(predicted_as_para[im])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
